# pandas
# 시리즈, 데이터 프레임
# 데이터 프레임: 시리즈의 조합
# 데이터 프레임으로 데이터 분석을 함.
# 데이터 프레임은 엑셀의 표 형태로 되어 있음.
# 시리즈: 1차원 어레이 형태로 되어 있음.
# 시리즈 학습
# 시리즈 생성 방법

import numpy as np
import pandas as pd

arr = np.arange(100, 110)

s1 = pd.Series(arr)
s1
출력
0    100
1    101
2    102
3    103
4    104
5    105
6    106
7    107
8    108
9    109
dtype: int32

# numpy의 array를 이용해서 시리즈 s2를 만들어 보세요
import numpy as np
import pandas as pd

arr2= np.arange(2, 10, 2)

s2 = pd.Series(arr2)
s2
출력
0    2
1    4
2    6
3    8
dtype: int32

# python의 list를 이용한 시리즈 생성
s3 = pd.Series([1, 2, 3, 4, 5, 6, 7])
s3
출력
0    1
1    2
2    3
3    4
4    5
5    6
6    7
dtype: int64

arr3 = np.array([1, 11, 111, 1111, 11111])
s4 = pd.Series(arr3)
s4
출력
0        1
1       11
2      111
3     1111
4    11111
dtype: int32

s5 = pd.Series(["안녕", "hello", "hi", "ohayo", 1, 2])
s5
출력
0       안녕
1    hello
2       hi
3    ohayo
4        1
5        2
dtype: object

# 시리즈 생성은 여기까지
# range index

s1.index
출력
RangeIndex(start=0, stop=10, step=1)

s1[0]      s1[1]
출력 
100       101    

s2[0]
출력
2

s2[-1]
출력
에러뜸
# 출력값은 에러뜸
# 파이썬의 인덱싱과 다름.
# 파이썬의 각 모듈은 하나의 언어의 개념이다

# 맨마지막 레인지 인덱스 값(최대값)을 가져오려면..
s2[len(s2)-1]
출력
8

# boolean indexing = mask
s1 > 103      # 타입은 bool
출력
0    False
1    False
2    False
3    False
4     True
5     True
6     True
7     True
8     True
9     True
dtype: bool

s1[s1 > 103]
출력
4    104
5    105
6    106
7    107
8    108
9    109
dtype: int32

# 팬시 인덱싱
# 2번과 7번 인덱싱
s1
출력
0    100
1    101
2    102
3    103
4    104
5    105
6    106
7    107
8    108
9    109
dtype: int32

# 팬시 인덱싱
s1[ [2, 7]]
출력
2    102
7    107
dtype: int32

# range index: 1, 6, 8
# 팬시 인덱싱 하기
s1[[1, 6, 8]]
출력
1    101
6    106
8    108
dtype: int32

# boolean indexing = mask
# s1의 요솟값들 중 3의 배수만 인덱싱하기
# 3으로 나누었을 때, 나머지가 0일 때, 3의 배수임
s1[s1 % 3 == 0]
출력
2    102
5    105
8    108
dtype: int32

# 슬라이스 인덱싱
s1[:]
출력
0    100
1    101
2    102
3    103
4    104
5    105
6    106
7    107
8    108
9    109
dtype: int32

s1[:3]
출력
0    100
1    101
2    102
dtype: int32

s1[2:6]
출력
2    102
3    103
4    104
5    105
dtype: int32

# 레인지인덱스 변경하기
s6 = pd.Series(["hello", "hi", "안녕"], index=["a", "b", "c"])
s6
출력
a    hello
b       hi
c       안녕
dtype: object

# hi 인덱싱 하기
s6['b']
출력
'hi'

s6[['a','b']]
출력
a    hello
b       hi
dtype: object

s6[1]  # 눈에 보이지 않지만 기존에 있던 레인지인덱스도 사용할 수 있다.
출력
'hi'

s6[[1]]  # 출력값은 시리즈 상태로 나옴
출력
b    hi
dtype: object

s2.index   # 2~5까지는 똑같이 나옴
출력
RangeIndex(start=0, stop=4, step=1)

s6.index
출력
Index(['a', 'b', 'c'], dtype='object')

# 사용자 인덱스로 바꾸기
s1.index = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']
s1
출력
a    100
b    101
c    102
d    103
e    104
f    105
g    106
h    107
i    108
j    109
dtype: int32

# list로 레인지인덱스 바꾸기
s2.index = list("worl")
s2
출력
w    2
o    4
r    6
l    8
dtype: int32

# 속성과 함수는 다릅니다
# 표현 형태에 있어서, 
# 속성은 속성명만 적음
# 함수는 함수명()

s1.values  # array형태로 출력됨
출력
array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])

s1[:]
출력
a    100    시리즈로 나옴
b    101
c    102
d    103
e    104
f    105
g    106
h    107
i    108
j    109
dtype: int32

s1.ndim  # 1차원 형태로 나옴
출력
1

s1.shape
출력
(10,)

# NaN를 넣고 싶을 떄 -> None을 사용해도 되지만 np.nan를 많이 사용한다
s7 = pd.Series([1, 2, 3, 4, 5, np.nan, 7, 8])
s7
출력
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    NaN
6    7.0
7    8.0
dtype: float64

# null값이 있냐?
s7.isnull()
출력
0    False
1    False
2    False
3    False
4    False
5     True
6    False
7    False
dtype: bool

s7.isna()
출력
0    False
1    False
2    False
3    False
4    False
5     True
6    False
7    False
dtype: bool

s7.notnull()
출력
0     True
1     True
2     True
3     True
4     True
5    False
6     True
7     True
dtype: bool

# s7에서 값이 nan인 요솟값을 출력하시오
s7[s7.isna()]          또는  s7[s7.isnull()]
출력
5   NaN
dtype: float64

# s7에서 값이 nan이 아닌 요솟값들을 인덱싱하세요
s7[s7.notnull()]
출력
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
6    7.0
7    8.0
dtype: float64

# s7에게 사용자 인덱스 부여
s7.index = list("hiworldy")
s7
출력
h    1.0
i    2.0
w    3.0
o    4.0
r    5.0
l    NaN
d    7.0
y    8.0
dtype: float64

# s7에서 사용자 인덱스 i, r 인덱싱하기
s7[['i', 'r']]
출력
i    2.0
r    5.0
dtype: float64

#######################
pandasex2(dataframe) 생성

# dataframe 학습

import pandas as pd
import numpy as np

s1 = pd.Series([1, 2, 3, 4, 5])
s2 = pd.Series(['a', 'b', 'c', 'd', 'e'])
df1 = pd.DataFrame(s1, s2)
df1
출력  표가 나옴
	0
a	NaN
b	NaN
c	NaN
d	NaN
e	NaN

df2 = pd.DataFrame({"s1":s1, "s2":s2})
df2
출력
	s1	s2
0	1	a
1	2	b
2	3	c
3	4	d
4	5	e

df3 = pd.DataFrame([1, 2, 3, 4],
                  [5, 6, 7, 8])
df3
# 1,2,3,4 는 데이터
# 5,6,7,8 은 인덱스
# 0 은 컬럼명
출력

           0
5	1
6	2
7	3
8	4

df4 = pd.DataFrame([[1, 2, 3, 4]],
                  index=[5, 6, 7, 8])
df4
출력
           0
5	1
6	2
7	3
8	4	


df5 = pd.DataFrame(
    [
        [1, 2, 3, 4],
        ["kim", 'lee', 'park', 'jung'],
        ['서울', '서울', '제주', '강원']
    ]
)
df5
출력
	0	1	2	3
0	1	2	3	4
1	kim	lee	park	jung
2	서울	서울	제주	강원

df6 = pd.DataFrame({
    'id':[1, 2, 3, 4], 
    'name': ["kim", 'lee', 'park', 'jung'],
    'addr': ['서울', '서울', '제주', '강원']
})
df6
출력

           id        name	addr
0	1	kim	서울
1	2	lee	서울
2	3	park	제주
3	4	jung	강원

# df7 변수에 데이터프레임 객체를 넣으세요
df7 = pd.DataFrame({
    'name': ['kim', 'lee', 'park'],
    'kr': [100 ,90, 80],
    'eng': [80, 90, 100]
})
df7
출력
          name	kr	eng
0	kim	100	80
1	lee	90	90
2	park	80	100

# 컬럼명 같이 넣기
df8 = pd.DataFrame(
    [
        [1, 'kim', '서울'],
        [2, 'lee', '서울'],
        [3, 'park', '제주'],
        [4, 'jung', '강원']
    ],
    columns=["번호", '이름', '주소']
)

df8   
출력

         번호	이름	주소
0	1	kim	서울
1	2	lee	서울
2	3	park	제주
3	4	jung	강원

# 컬럼명만 바꾸기
df8.columns = ['num', 'name', 'addr']
df8
출력
          num	name	addr
0	1	kim	서울
1	2	lee	서울
2	3	park	제주
3	4	jung	강원

ser1 = df8['num']
# 타입은 시리즈로 나옴
ser1
출력
0    1
1    2
2    3
3    4
Name: num, dtype: int64

# ser1에서 3을 추출하기
ser1[2]
출력
3

# ser1에서 4를 추출하기
df8['num'][3]
출력
4

# df8의 최종요솟값 중 park 가져오기
df8['name'][2]
출력
'park'

# df8의 최종요솟값 중 kim, jung 가져오기
# 힌트 팬시 인덱싱
df8['name'][[0,3]]
출력
0     kim
3    jung
Name: name, dtype: object

# 컬럼 전체를 가져오거나, 컬럼의 특정 요솟값 가져오기는 잘 했음
# 행(row) 정보 가져오기

# 행을 인덱싱 하고 싶으면 
# 슬라이싱 형태로 인덱싱하면 된다
df8[0:2]
출력
          num	name	addr
0	1	kim	서울
1	2	lee	서울

# 행 2번만 가져오고 싶으면..
df8.loc[2]
출력
num        3
name    park
addr      제주
Name: 2, dtype: object

# 행 0번 과 2번만 가져오고 싶으면..
# 팬시 인덱싱으로 하면 된다.
df8.loc[[0, 2]]
출력
	num	name	addr
0	1	kim	서울
2	3	park	제주

df81 = df8.loc[[0, 1, 3]]
df81
출력
         num	name	addr
0	1	kim	서울
1	2	lee	서울
3	4	jung	강원

df81[['num', 'addr']]            또는   df8.loc[[0, 1, 3]][['num', 'addr']]
출력                                        df81을 대입햇던 df8.loc[[0, 1, 3]]를 넣은것임
         num	addr
0	1	서울
1	2	서울
3	4	강원

# df9 생성하고,
# 인덱스가 0인 row를 추출하시오
df9 = pd.DataFrame({
    'id' : ['m1', 'm2', 'm3', 'm4', 'm5'],
    'name' : ['kim', 'lee', 'park', 'jung', 'choi'],
    'age' : [10, 20, 30, 40, 50]
}) 

df9
df9.loc[0]
출력
id       m1
name    kim
age      10
Name: 0, dtype: object

# name 과 age만 가져오기
df9.loc[0][['name', 'age']]
출력
name    kim
age      10
Name: 0, dtype: object

df9.iloc[:]
출력
	id	name	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	m5	choi	50

df9.iloc[:, 2]  # : 는 행 다가져온다는 의미
출력
0    10
1    20
2    30
3    40
4    50
Name: age, dtype: int64

# 행과 열이 만나는 요솟값 
df9.iloc[1, 2] 
출력
20

df9.loc[1, 'age']
출력
20

# iloc 와 loc 차이점
# 행 정보를 추출할 때는 loc든 iloc든 맘대로 사용하세요
# 그런데 컬럼 정보를 추출할 때, 
# -컬럼명으로 추출할 때는 loc
# -컬럼의 인덱스로 추출할 때는 iloc , i는 인덱스의 약자임


# 마스크 인덱싱 작업
df9['age'] > 30
출력
0    False
1    False
2    False
3     True
4     True
Name: age, dtype: bool

df9[df9['age'] > 30]
출력
	id	name	age
3	m4	jung	40
4	m5	choi	50

df9.iloc[:, 0:2]  
# [:, 0:2] 슬라이싱 인덱싱 이용
# 또는 [:, [0, 1]] 팬시인덱싱 이용
출력
	id	name
0	m1	kim
1	m2	lee
2	m3	park
3	m4	jung
4	m5	choi

df9.filter(items=['id', 'age'])    # df9[['id', 'age']] 팬시인덱싱하고 같다
출력
	id	age
0	m1	10
1	m2	20
2	m3	30
3	m4	40
4	m5	50

df9.filter(like='a', axis=1)  # a라는 컬럼명을 찾으라는 의미
출력
           name	age
0	kim	10
1	lee	20
2	park	30
3	jung	40
4	choi	50

df9.filter(regex='e$', axis=1)   # e자로 끝나는 컬럼명을 찾으라는 의미
출력
	name	age
0	kim	10
1	lee	20
2	park	30
3	jung	40
4	choi	50

df9.iloc[0:2, [0, 2]]
출력
	id	age
0	m1	10
1	m2	20

# drop
# pandas의 구조 database 테이블의 구조와 유사합니다
# 데이블의 컬럼 삭제를 drop
# pandas의 컬럼을 삭제하는 것을 drop이라고 합니다
# 테이블의 로우(행)을 삭제한다. delete
# pandas에서는 row 삭제를 drop이라고 합니다

df2.drop([1])  # 출력값을 보면 삭제된 것처럼 보이지만 다시 df2를 실행하면 원래대로 나온다
출력
	s1	s2
0	1	a
2	3	c
3	4	d
4	5	e

df2.drop([1, 2], inplace=True)   # 변경된 내용으로 저장이 된다
df2
출력
           s1	s2
0	1	a
3	4	d
4	5	e

df6
출력
           id	name	addr
0	1	kim	서울
1	2	lee	서울
2	3	park	제주
3	4	jung	강원

df6['name'] == 'lee'
출력
0    False
1     True
2    False
3    False
Name: name, dtype: bool

df6[df6['name'] == 'lee']
출력
           id	name	addr
1	2	lee	서울

# row를 drop하는 방법
# -drop()함수
# - []인덱싱 이용하는 방법

df6.drop("addr", axis=1)  # addr를 삭제함
출력
	id
0	1
1	2
2	3
3	4

df6.drop("name", inplace=True, axis=1) 
df6
출력
           id	addr
0	1	서울
1	2	서울
2	3	제주
3	4	강원

df6['name'] = ['kim', 'lee', 'park', 'jung']  # name 삭제된거 다시 살리기
df6
출력
           id	addr	name
0	1	서울	kim
1	2	서울	lee
2	3	제주	park
3	4	강원	jung

#########################################
# 파일 저장하기
df6.to_csv('first.csv')
# 쥬피터파이썬에 파일이 생성됨

df6.to_csv('first2.csv', index=False)  # 인덱스는 없애고 데이터만 들어가 있음

df6.to_csv('first3.csv', index=False, header=None) # id,name,addr 빼버림

# 파일 읽어오기
df21 = pd.read_csv("first.csv")
df21
출력
    Unnamed: 0	id	addr	name
0	0	1	서울	kim
1	1	2	서울	lee
2	2	3	제주	park
3	3	4	강원	jung

# df21에서 Unnamed: 0	컬럼을 삭제해주세요
df21.drop("Unnamed: 0", inplace=True, axis=1) 
df21
출력
	id	addr	name
0	1	서울	kim
1	2	서울	lee
2	3	제주	park
3	4	강원	jung

df22 = pd.read_csv("first2.csv")
df22
출력
           id	addr	name
0	1	서울	kim
1	2	서울	lee
2	3	제주	park
3	4	강원	jung

df23 = pd.read_csv("first3.csv", header=None) # 컬럼명이 없을떈 header=None 입력하면 임의로 생긴다
df23
출력
           0	1	2
0	1	서울	kim
1	2	서울	lee
2	3	제주	park
3	4	강원	jung

# df23에서 임의로 생선된 컬럼명을 다시 넣어 주세요
df23.columns = ['id', 'addr', 'name']
df23
출력
           id	addr	name
0	1	서울	kim
1	2	서울	lee
2	3	제주	park
3	4	강원	jung

##########################
# df9를 second1.csv: idex 존재, 헤더도 존재
# df9를 second2.csv: 인덱스 없음, 헤더 존재
# df9를 second3.csv: 인덱스 없음, 헤더 없음

# df31: second1.csv를 읽어 옴
# df32: second2.csv를 읽어 옴
# df33: second3.csv를 읽어 옴

df9.to_csv('second1.csv')
df9.to_csv('second2.csv', index=False)
df9.to_csv('second3.csv', index=False, header=None)

df31 = pd.read_csv('second1.csv')
df31
df31.drop('Unnamed: 0', axis=1, inplace=True)
df31
출력
     Unnamed: 0	id	name	age
0	0	m1	kim	10
1	1	m2	lee	20
2	2	m3	park	30
3	3	m4	jung	40
4	4	m5	choi	50

df32 = pd.read_csv('second2.csv')
df32
출력
            id	name	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	m5	choi	50

df33 = pd.read_csv('second3.csv', header=None)
df33
df33.columns = ['id', 'name', 'age']
df33
출력
           m1	kim	10
0	m2	lee	20
1	m3	park	30
2	m4	jung	40
3	m5	choi	50   데이터값이 헤더에 있음


df9.to_csv("third.txt", sep='\t', index=False)  # 탭으로 간격을 떨어뜨릴때 sep='\t'

df41 = pd.read_csv('third.txt', sep='\t') # sep='\t'빼고 출력하면 역슬러시t 로 출력이 된다
df41
출력
	id	name	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	m5	choi	50

####################
pandasex3 생성

import pandas as pd

df1 = pd.DataFrame({
    'id':['m1', 'm2', 'm3', 'm4'],
    'name': ['kim', 'lee', 'park', 'jung']
})

df2 = pd.DataFrame({
    'age':[10, 20, 30, 40]
})

# df1과 df2 합치기
result1 = pd.concat([df1, df2], axis=1)   # concat() 나오면 합치기 이구나라고 생각하면 됨
result1
출력
	id	name	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40

df3 = pd.DataFrame({
    'id' : [4, 5],
    'name' : ['kim', 'lee'],
    'age' : [10, 10]
})
df3
출력
	id	name	age
0	4	kim	10
1	5	lee	10

# result와 df3을 병합하기
pd.concat([result1, df3], axis=0, ignore_index=True) 
# ignore_index=True 쓰면 레인지인덱스 번호가 순서대로 나열된다
출력
           id	name	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	4	kim	10
5	5	lee	10

result1 = pd.concat([result1, df3], axis=0, ignore_index=True)
result1

result1.T   # 행과 열이 바뀐다
출력
	0	1	2	3	4	5
id	m1	m2	m3	m4	4	5
name	kim	lee	park	jung	kim	lee
age	10	20	30	40	10	10

result1.value_counts()
출력
id  name  age
4   kim   10     1
5   lee   10     1
m1  kim   10     1
m2  lee   20     1
m3  park  30     1
m4  jung  40     1
dtype: int64

result1['age'].value_counts()   # 같은 값을 숫자로 세어준다
출력
10    3
20    1
30    1
40    1
Name: age, dtype: int64

result1['name'].value_counts()
출력
kim     2
lee     2
park    1
jung    1
Name: name, dtype: int64

# 컬럼명 바꾸기
result1.rename(columns={'id':'아이디', 'name':'성명'}, inplace=True)
result1
출력
          아이디	성명	age
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	4	kim	10
5	5	lee	10

# 나이 컬럼명 바꾸기
result1.rename(columns={'age':'나이'}, inplace=True)
result1
출력
	아이디	성명	나이
0	m1	kim	10
1	m2	lee	20
2	m3	park	30
3	m4	jung	40
4	4	kim	10
5	5	lee	10


# ratings.dat 파일을
# read_csv()함수로 읽어 오시오
df4 = pd.read_csv('ratings.dat', header=None, delimiter="::", engine='python')

df4.head()
df4.tail()
출력
             0	1	2	3
1000204	6040	1091	1	956716541
1000205	6040	1094	5	956704887
1000206	6040	562	5	956704746
1000207	6040	1096	4	956715648
1000208	6040	1097	4	956715569

df4.shape
출력
(1000209, 4)

# 0: uid,  1:mid,  2:rating,  3:time 으로 컬럼명 바꾸기
df4.columns=['uid', 'mid', 'rating', 'time']

df4.head(10)
출력
          uid	mid	rating	time
0	1	1193	5	978300760
1	1	661	3	978302109
2	1	914	3	978301968
3	1	3408	4	978300275
4	1	2355	5	978824291
5	1	1197	3	978302268
6	1	1287	5	978302039
7	1	2804	5	978300719
8	1	594	4	978302268
9	1	919	4	978301368

# 잘못된 데이터가 있는지 확인하기
df4.isnull().value_counts()
출력
uid    mid    rating  time 
False  False  False   False    1000209
dtype: int64

df4.describe() # 통계적인 분석을 보여준다
출력
	      uid                 mid	               rating	                time
count	1.000209e+06	1.000209e+06	1.000209e+06	1.000209e+06
mean	3.024512e+03	1.865540e+03	3.581564e+00	9.722437e+08
std	1.728413e+03	1.096041e+03	1.117102e+00	1.215256e+07
min	1.000000e+00	1.000000e+00	1.000000e+00	9.567039e+08
25%	1.506000e+03	1.030000e+03	3.000000e+00	9.653026e+08
50%	3.070000e+03	1.835000e+03	4.000000e+00	9.730180e+08
75%	4.476000e+03	2.770000e+03	4.000000e+00	9.752209e+08
max	6.040000e+03	3.952000e+03	5.000000e+00	1.046455e+09
rating 만 나와야하는데 다 나와버림


df4['rating'].head()    # 'rating'을 .앞에 쓰는 이유는 .뒤에 쓰게 되면 다른값을 바꿔서 쓸수가 없다.
출력
0    5
1    3
2    3
3    4
4    5
Name: rating, dtype: int64

def haha(colname):
    df4[rating].head()   # rating변수니깐 "" 안쓴다

df4['rating'].mean()
출력
3.581564453029317

# rating이 1인 영화들을 추출하시오
df4[df4['rating'] == 1]['mid'].unique().shape   # unique()중복되지 않게 가져와라
출력
(3274,)

df4[df4['rating'] == 1].duplicated('mid').value_counts() 
# duplicated('mid') mid가 중복되는게 있냐 라는 뜻
# value_counts() 갯수 세기
출력
True     52900
False     3274
dtype: int64

df4[df4['rating'] == 1].drop_duplicates(['mid'], keep='first')
# drop_duplicates(['mid'], keep='first') 는
# 중복된거는 삭제 되는데 첫번째꺼는 유지(삭제x) 시킨다는 의미임








































































































































































































